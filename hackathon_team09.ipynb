{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hackathon_team09",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snapperbay4453/2020_cau_oss_hackathon/blob/master/hackathon_team09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1AosAX9DXOlc"
      },
      "source": [
        "# **0. 해커톤 진행 주의사항**\n",
        "\n",
        "**1)  개발 관련 주의사항**\n",
        "*   [1. 초기 환경 설정]은 절대 수정하지 말 것\n",
        "*   모든 구현은 [2. 데이터 전처리] 및 [3.모델 생성]에서만 진행\n",
        "*   [4. 모델 저장]에서 team_name 변수 변경 (예.`team_name = 'team01'`)\n",
        " *    트레이닝 중간에 checkpoint를 활용하여 모델을 저장한 경우에도 파일 이름 양식 통일 필수\n",
        "*   Colab 사용중 실수로 데이터 손실이 발생할 수도 있으니 중간 결과값을 github에 업로드 \n",
        " *    \"런타임->모든 런타임 재설정\"은 절대 누르지 말 것 (저장한 모델 데이터가 모두 삭제됨)\n",
        "*   효율적인 구현 및 테스팅을 위해 GPU 가속 기능 활성화\n",
        " *    \"런타임 -> 런타임 유형변경 -> 하드웨어 가속기 -> GPU 설정\"\n",
        "*   주석을 최대한 자세히 작성\n",
        "*   Keras API 관련하여 [Keras Documentation](https://keras.io/) 참조\n",
        "\n",
        "**2) 제출 관련 주의사항**\n",
        "*  제출물\n",
        " *  소스코드 (hackathon_teamXX.ipynb)\n",
        " *  컴파일된 모델 파일 (model_entire_teamXX.h5)\n",
        " *  모델 발표 자료 \n",
        "* 제출 기한: **오후 5시 (단, 발표자료는 11시)**\n",
        "* 제출 방법: [GitHub README](https://github.com/cauosshackathonta/2020_cau_oss_hackathon/) 참조\n",
        "\n",
        " \n",
        "**3) 평가 관련 주의사항**\n",
        "*  모델 성능 = 테스트 데이터 셋 분류 정확도\n",
        " *  model.evaluate(x_test, y_test)\n",
        "*  제출된 모델들의 테스트 데이터 셋 분류 정확도를 기준으로 수상작 결정\n",
        "*  수상 후보들에 대해서는 소스코드를 기반으로 모델 재검증 \n",
        " \n",
        "**4) 수상 실격 사유**\n",
        "*  유사한 소스코드 or 알고리즘이 적발될 경우\n",
        "*  소스코드와 제출된 모델이 상이한 경우\n",
        "*  개발 관련 주의사항을 지키지 않은 경우\n",
        " *  예: [초기 환경 설정]을 수정한 경우\n",
        "*  데이터 셋을 변조한 경우\n",
        " *  예. 테스트 데이터 셋을 트레이닝 데이터 셋에 포함하여 모델 생성 \n",
        "*  주석이 소스코드와 맞지 않거나 미비할 경우\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "67lwEXhUqys1"
      },
      "source": [
        "# **1. 초기 환경 설정**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ms5PBBJ1qSC6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "3d700f95-3424-4b88-dace-6cbf8e15add5"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals, unicode_literals\n",
        "\n",
        "# tensorflow와 tf.keras 및 관련 라이브러리 임포트\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# 데이터셋 다운로드\n",
        "check = !if [ -d 'dataset/' ]; then echo \"1\" ; else echo \"0\"; fi\n",
        "if (check[0] is '0' ):\n",
        "  !mkdir dataset\n",
        "  !wget 'https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/matlab.zip'\n",
        "  !unzip matlab.zip -d /content/dataset\n",
        "\n",
        "# 데이터셋 로드\n",
        "from scipy import io as spio\n",
        "emnist = spio.loadmat(\"/content/dataset/matlab/emnist-balanced.mat\")\n",
        "\n",
        "x_train = emnist[\"dataset\"][0][0][0][0][0][0]\n",
        "y_train = emnist[\"dataset\"][0][0][0][0][0][1]\n",
        "\n",
        "x_test = emnist[\"dataset\"][0][0][1][0][0][0]\n",
        "y_test = emnist[\"dataset\"][0][0][1][0][0][1]\n",
        "\n",
        "# # 분류를 위해 클래스 벡터를 바이너리 매트릭스로 변환\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "# 데이터 28x28 이미지화\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "# 총 클래스 개수\n",
        "num_classes = y_test.shape[1]\n",
        "input_shape = x_test.shape[1:]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-29 01:27:00--  https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/matlab.zip\n",
            "Resolving www.itl.nist.gov (www.itl.nist.gov)... 132.163.4.36, 2610:20:6b01:4::36\n",
            "Connecting to www.itl.nist.gov (www.itl.nist.gov)|132.163.4.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 743900280 (709M) [application/zip]\n",
            "Saving to: ‘matlab.zip’\n",
            "\n",
            "matlab.zip          100%[===================>] 709.44M  15.8MB/s    in 47s     \n",
            "\n",
            "2020-08-29 01:27:48 (15.2 MB/s) - ‘matlab.zip’ saved [743900280/743900280]\n",
            "\n",
            "Archive:  matlab.zip\n",
            "  inflating: /content/dataset/matlab/emnist-balanced.mat  \n",
            "  inflating: /content/dataset/matlab/emnist-byclass.mat  \n",
            "  inflating: /content/dataset/matlab/emnist-bymerge.mat  \n",
            "  inflating: /content/dataset/matlab/emnist-digits.mat  \n",
            "  inflating: /content/dataset/matlab/emnist-letters.mat  \n",
            "  inflating: /content/dataset/matlab/emnist-mnist.mat  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urb4fzGTQpS-",
        "colab_type": "text"
      },
      "source": [
        "테스트용 노트북"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A-YjppJpXBO9"
      },
      "source": [
        "# **2. 데이터 전처리**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QZ9KWTBP6AI1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f54edf5d-0fa7-4fcf-f586-8ebdd44a9101"
      },
      "source": [
        "# 데이터 전처리 (예: normalization)\n",
        "x_train_after = (x_train - np.mean(x_train)) / np.std(x_train)\n",
        "x_test_after = (x_test - np.mean(x_test)) / np.std(x_test)\n",
        "\n",
        "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=10,  \n",
        "    zoom_range = 0.1,  \n",
        "    width_shift_range=0.1, \n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    channel_shift_range=0.1\n",
        ")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndata_generator = tf.keras.preprocessing.image.ImageDataGenerator(\\n    rescale= 1.0 / 255,\\n    rotation_range=360,\\n    channel_shift_range=0.5,\\n    width_shift_range=0.5,\\n    height_shift_range=0.5,\\n    shear_range=0.5,\\n    zoom_range=0.5,\\n    horizontal_flip=True,\\n    vertical_flip=True\\n)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v-lo-O1yiFpY"
      },
      "source": [
        "# **3. 모델 생성**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DZP4eRmRqgRp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a35f07f1-91a6-4c27-d96d-d3d89596ef60"
      },
      "source": [
        "# 순차 모델 생성 (가장 기본구조)\n",
        "model = keras.Sequential()\n",
        "\n",
        "# 1차 히든 CNN 레이어 그룹\n",
        "model.add(keras.layers.Conv2D(filters = 128, kernel_size = (3, 3), input_shape = input_shape, activation='relu', padding = 'same'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Conv2D(filters = 128, kernel_size = (3, 3), activation='relu', padding = 'same'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Conv2D(filters = 128, kernel_size = (3, 3), activation='relu', padding = 'same'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "# 1차 풀링 및 드롭아웃 그룹\n",
        "model.add(keras.layers.MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(keras.layers.Dropout(rate = 0.5))\n",
        "\n",
        "# 2차 히든 CNN 레이어 그룹\n",
        "model.add(keras.layers.Conv2D(filters = 256, kernel_size = (3, 3), activation='relu', padding = 'same'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Conv2D(filters = 256, kernel_size = (3, 3), activation='relu', padding = 'same'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Conv2D(filters = 256, kernel_size = (3, 3), activation='relu', padding = 'valid'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "# 2차 풀링 및 드롭아웃 그룹\n",
        "model.add(keras.layers.MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(keras.layers.Dropout(rate = 0.5))\n",
        "\n",
        "# Flattern 레이어\n",
        "model.add(keras.layers.Flatten(input_shape = input_shape))\n",
        "\n",
        "# Dense 레이어 그룹\n",
        "model.add(keras.layers.Dense(units = 512, activation = 'relu'))\n",
        "model.add(keras.layers.Dense(units = 256, activation = 'relu'))\n",
        "model.add(keras.layers.Dense(units = num_classes, activation = tf.nn.softmax))\n",
        "\n",
        "# 모델 컴파일\n",
        "# optimizer: 모델을 업데이트 하는 방식\n",
        "# loss: 모델의 정확도를 판단하는 방식\n",
        "# metrics: 트레이닝 및 테스팅 성능 모니터링을 위한 평가지표\n",
        "\n",
        "#opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# 모델 과적합 방지를 위한 얼리스토퍼 생성\n",
        "early_stopper = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 5)\n",
        "\n",
        "# 체크포인트 생성\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath='/content/checkpoint_entire_best.h5', monitor='val_accuracy', verbose=1, save_weight_only=False, save_best_only=True, mode='auto')\n",
        "\n",
        "# 모델 트레이닝\n",
        "# batch_size: 전체 데이터셋 중 몇개씩 학습시킬 것인지\n",
        "# epoch: 학습에 전체 데이터셋이 총 몇번 이용될 것인지\n",
        "# shuffle: 학습전에 트레이닝 데이터셋을 랜덤하게 섞을 것인지\n",
        "# validation_data: 중간 성능 검증에 사용할 data set\n",
        "\n",
        "history = model.fit_generator(\n",
        "    data_generator.flow(x_train_after, y_train, batch_size=128),\n",
        "    epochs = 1000, shuffle = True,\n",
        "    callbacks=[early_stopper, cp_callback],\n",
        "    validation_data=(x_test_after, y_test)\n",
        ")"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_50\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_211 (Conv2D)          (None, 28, 28, 128)       1280      \n",
            "_________________________________________________________________\n",
            "batch_normalization_63 (Batc (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_212 (Conv2D)          (None, 28, 28, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_64 (Batc (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_213 (Conv2D)          (None, 28, 28, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_65 (Batc (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_85 (MaxPooling (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_132 (Dropout)        (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_214 (Conv2D)          (None, 14, 14, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_66 (Batc (None, 14, 14, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_215 (Conv2D)          (None, 14, 14, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_67 (Batc (None, 14, 14, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_216 (Conv2D)          (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_68 (Batc (None, 12, 12, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_86 (MaxPooling (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_133 (Dropout)        (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_46 (Flatten)         (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_127 (Dense)            (None, 512)               4719104   \n",
            "_________________________________________________________________\n",
            "dense_128 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_129 (Dense)            (None, 47)                12079     \n",
            "=================================================================\n",
            "Total params: 6,638,895\n",
            "Trainable params: 6,636,591\n",
            "Non-trainable params: 2,304\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "  2/882 [..............................] - ETA: 37s - loss: 7.9457 - accuracy: 0.0156   WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0309s vs `on_train_batch_end` time: 0.0535s). Check your callbacks.\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.9089 - accuracy: 0.7299\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.82223, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 64s 73ms/step - loss: 0.9089 - accuracy: 0.7299 - val_loss: 0.5264 - val_accuracy: 0.8222\n",
            "Epoch 2/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.4648 - accuracy: 0.8381\n",
            "Epoch 00002: val_accuracy improved from 0.82223 to 0.84851, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 64s 72ms/step - loss: 0.4648 - accuracy: 0.8381 - val_loss: 0.4468 - val_accuracy: 0.8485\n",
            "Epoch 3/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.4083 - accuracy: 0.8537\n",
            "Epoch 00003: val_accuracy improved from 0.84851 to 0.85835, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 64s 72ms/step - loss: 0.4083 - accuracy: 0.8537 - val_loss: 0.4022 - val_accuracy: 0.8584\n",
            "Epoch 4/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.3798 - accuracy: 0.8626\n",
            "Epoch 00004: val_accuracy improved from 0.85835 to 0.87005, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 64s 72ms/step - loss: 0.3798 - accuracy: 0.8626 - val_loss: 0.3624 - val_accuracy: 0.8701\n",
            "Epoch 5/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.3594 - accuracy: 0.8682\n",
            "Epoch 00005: val_accuracy improved from 0.87005 to 0.87957, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 64s 72ms/step - loss: 0.3594 - accuracy: 0.8682 - val_loss: 0.3514 - val_accuracy: 0.8796\n",
            "Epoch 6/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.3468 - accuracy: 0.8720\n",
            "Epoch 00006: val_accuracy did not improve from 0.87957\n",
            "882/882 [==============================] - 64s 72ms/step - loss: 0.3468 - accuracy: 0.8720 - val_loss: 0.3345 - val_accuracy: 0.8790\n",
            "Epoch 7/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.3355 - accuracy: 0.8758\n",
            "Epoch 00007: val_accuracy improved from 0.87957 to 0.88622, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 63s 72ms/step - loss: 0.3355 - accuracy: 0.8758 - val_loss: 0.3167 - val_accuracy: 0.8862\n",
            "Epoch 8/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.3242 - accuracy: 0.8791\n",
            "Epoch 00008: val_accuracy improved from 0.88622 to 0.88979, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 63s 72ms/step - loss: 0.3242 - accuracy: 0.8791 - val_loss: 0.3118 - val_accuracy: 0.8898\n",
            "Epoch 9/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.3156 - accuracy: 0.8821\n",
            "Epoch 00009: val_accuracy did not improve from 0.88979\n",
            "882/882 [==============================] - 63s 72ms/step - loss: 0.3156 - accuracy: 0.8821 - val_loss: 0.3349 - val_accuracy: 0.8805\n",
            "Epoch 10/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.3060 - accuracy: 0.8858\n",
            "Epoch 00010: val_accuracy did not improve from 0.88979\n",
            "882/882 [==============================] - 63s 72ms/step - loss: 0.3060 - accuracy: 0.8858 - val_loss: 0.3384 - val_accuracy: 0.8797\n",
            "Epoch 11/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.3021 - accuracy: 0.8864\n",
            "Epoch 00011: val_accuracy improved from 0.88979 to 0.89144, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 63s 72ms/step - loss: 0.3021 - accuracy: 0.8864 - val_loss: 0.3176 - val_accuracy: 0.8914\n",
            "Epoch 12/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.2949 - accuracy: 0.8888\n",
            "Epoch 00012: val_accuracy did not improve from 0.89144\n",
            "882/882 [==============================] - 63s 72ms/step - loss: 0.2949 - accuracy: 0.8888 - val_loss: 0.3261 - val_accuracy: 0.8838\n",
            "Epoch 13/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.2901 - accuracy: 0.8894\n",
            "Epoch 00013: val_accuracy did not improve from 0.89144\n",
            "882/882 [==============================] - 63s 72ms/step - loss: 0.2901 - accuracy: 0.8894 - val_loss: 0.3110 - val_accuracy: 0.8897\n",
            "Epoch 14/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.2831 - accuracy: 0.8921\n",
            "Epoch 00014: val_accuracy did not improve from 0.89144\n",
            "882/882 [==============================] - 63s 72ms/step - loss: 0.2831 - accuracy: 0.8921 - val_loss: 0.3248 - val_accuracy: 0.8861\n",
            "Epoch 15/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.2798 - accuracy: 0.8930\n",
            "Epoch 00015: val_accuracy did not improve from 0.89144\n",
            "882/882 [==============================] - 63s 72ms/step - loss: 0.2798 - accuracy: 0.8930 - val_loss: 0.3177 - val_accuracy: 0.8870\n",
            "Epoch 16/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.2730 - accuracy: 0.8952\n",
            "Epoch 00016: val_accuracy improved from 0.89144 to 0.89559, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 64s 72ms/step - loss: 0.2730 - accuracy: 0.8952 - val_loss: 0.3014 - val_accuracy: 0.8956\n",
            "Epoch 17/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.2693 - accuracy: 0.8963\n",
            "Epoch 00017: val_accuracy improved from 0.89559 to 0.89622, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 63s 72ms/step - loss: 0.2693 - accuracy: 0.8963 - val_loss: 0.3008 - val_accuracy: 0.8962\n",
            "Epoch 18/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.2653 - accuracy: 0.8963\n",
            "Epoch 00018: val_accuracy did not improve from 0.89622\n",
            "882/882 [==============================] - 63s 72ms/step - loss: 0.2653 - accuracy: 0.8963 - val_loss: 0.3061 - val_accuracy: 0.8926\n",
            "Epoch 19/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.2616 - accuracy: 0.8977\n",
            "Epoch 00019: val_accuracy did not improve from 0.89622\n",
            "882/882 [==============================] - 63s 72ms/step - loss: 0.2616 - accuracy: 0.8977 - val_loss: 0.2990 - val_accuracy: 0.8955\n",
            "Epoch 20/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.2591 - accuracy: 0.8995\n",
            "Epoch 00020: val_accuracy did not improve from 0.89622\n",
            "882/882 [==============================] - 63s 71ms/step - loss: 0.2591 - accuracy: 0.8995 - val_loss: 0.2932 - val_accuracy: 0.8951\n",
            "Epoch 21/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.2558 - accuracy: 0.9007\n",
            "Epoch 00021: val_accuracy did not improve from 0.89622\n",
            "882/882 [==============================] - 63s 72ms/step - loss: 0.2558 - accuracy: 0.9007 - val_loss: 0.3023 - val_accuracy: 0.8950\n",
            "Epoch 22/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.2521 - accuracy: 0.9007\n",
            "Epoch 00022: val_accuracy improved from 0.89622 to 0.89771, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 63s 72ms/step - loss: 0.2521 - accuracy: 0.9007 - val_loss: 0.3003 - val_accuracy: 0.8977\n",
            "Epoch 23/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.2491 - accuracy: 0.9026\n",
            "Epoch 00023: val_accuracy did not improve from 0.89771\n",
            "882/882 [==============================] - 63s 72ms/step - loss: 0.2491 - accuracy: 0.9026 - val_loss: 0.2994 - val_accuracy: 0.8940\n",
            "Epoch 24/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.2476 - accuracy: 0.9033\n",
            "Epoch 00024: val_accuracy did not improve from 0.89771\n",
            "882/882 [==============================] - 63s 72ms/step - loss: 0.2476 - accuracy: 0.9033 - val_loss: 0.3158 - val_accuracy: 0.8887\n",
            "Epoch 25/1000\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.2438 - accuracy: 0.9047\n",
            "Epoch 00025: val_accuracy did not improve from 0.89771\n",
            "882/882 [==============================] - 63s 72ms/step - loss: 0.2438 - accuracy: 0.9047 - val_loss: 0.3046 - val_accuracy: 0.8947\n",
            "Epoch 00025: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV6eWheKXyhn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "685eda3b-bd0c-4814-c20c-7d1d54890c9a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize = (10, 5))\n",
        "\n",
        "plt.plot(history.history['loss'], 'b-', label = 'train')\n",
        "plt.plot(history.history['val_loss'], 'r-', label = 'val')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QR9WUYXxqtfR"
      },
      "source": [
        "# **4. 모델 저장**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wi9yznz4qvzK",
        "colab": {}
      },
      "source": [
        "save_path = '/content/'\n",
        "team_name = 'team09'\n",
        "\n",
        "# 트레이닝된 전체 모델을 저장합니다.\n",
        "model.save(save_path +  'model_entire_'+ team_name + '.h5')"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4aPbgI-c-Kj8"
      },
      "source": [
        "# **5. 모델 로드 및 평가**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y7WONVxH-Kt6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9a662cb2-3be1-423e-982b-e002887fb1b2"
      },
      "source": [
        "save_path = '/content/'\n",
        "team_name = 'team09'\n",
        "\n",
        "model = keras.models.load_model(save_path + 'model_entire_' + team_name + '.h5')\n",
        "\n",
        "model.evaluate(x_test_after, y_test)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "588/588 [==============================] - 4s 7ms/step - loss: 0.3046 - accuracy: 0.8947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.30462366342544556, 0.8947340250015259]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    }
  ]
}